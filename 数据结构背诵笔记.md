# 数据结构背诵笔记(有些内容待补充 标记：danger)
## 线性表
* 结构
    * 顺序存储（物理上）——顺序表
    * 链式存储
        * 单链表
        * 双链表
        * 循环链表
        * 静态链表
### 线性表的定义
* 线性表是一个逻辑概念，是具有相同数据类型的n（n$\geq$0）个数据元素的有限序列；其物理实现通过顺序存储和链式存储来实现
* L=（a<sub>1</sub>,a<sub>2</sub>,……,a<sub>n</sub>）
    * a<sub>1</sub>是表头元素，a<sub>n</sub>是表尾元素
    * 除表头每个元素都有一个直接前驱，除表尾每个元素都有一个直接后继
    * 特点
        * 个数有限
        * 有顺序性
        * 都是数据元素，且都是单个元素
        * 数据元素类型相同，意味着每个元素占有相同大小的存储空间
### 线性表的基本操作
* 就是那些操作了（代码实现）
### 线性表的实现
#### 顺序表示
* 用一组**地址连续的存储单元**依次存储线性表中的数据元素，从而使逻辑上相邻的两个元素在物理位置上也相邻
* 线性表的位序从1开始，数组元素下标从0开始
* 数组的静态分配 vs 动态分配
* 评价
    * 随机访问，时间复杂度O(1)
    * 存储密度高
    * 插入和删除需要移动大量的元素
    * 时间复杂度
        * 插入：平均（0+1+2+……+n）/(n+1)=n/2
        * 删除：平均 (0+1+2+……+n-1)/n=(n-1)/2
        * 按值查找（顺序查找）：（1+2+……+n）/n=（n+1）/2
#### 链式表示
* 顺序表可以随机存取，但是插入和删除需要移动大量元素。而链式存储，不需要使用地址连续的存储单元，通过链建立起元素之间的逻辑关系，因此插入和删除操作不需要移动元素，但是不可以顺序存储。
##### 单链表
* 即线性表的链式存储
* 结构

data|next|
--|--|
* 评价
    * 解决了顺序表需要大量连续存储单元的问题
    * 但是单链表附加指针域，存在浪费空间的缺点
    * 不能随机存取
* 头指针 vs 头结点
    * 通常用头指针标识一个单链表，当头指针为null时表示一个空表
    * 为了操作方面，可以在第一个结点之前附加一个结点，称为头结点，头结点的指针域指向第一个结点，其数据域不设信息，或者记录表长等信息
    * 不论带不带头结点，头指针始终指向链表的第一个结点
    * 引入头结点后
        * 第一个数据结点的操作与其他位置一致，不用特殊操作，思考插入，删除，第一个数据结点与其他结点统一
        * 无论链表是否为空，头结点都指向头结点的非空指针（但头结点的指针域为空），空表和非空表统一
* 基本操作
    * 建立
        * 头插法
            * 头插法操作简单，但是读入和生成顺序不一致
        * 尾插法
            * 需要设置一个尾指针++
    * 查找 
        * 查找操作的时间复杂度一般都为O(n)
    * 插入/删除
        * 插入/删除操作的时间复杂度为O(n)，主要用在查找之上
##### 双链表
* 双链表与单链表
    * 单链表只有一个指向后继的指针，只能方便的访问其后继结点，为O(1)，但是访问其前驱结点时，却需要O(n)
    * 为克服单链表的这个缺点，引入了双链表，其还有前驱和后继两个指针，prior和next
* 查找操作与单链表一致
* 但因为出现了prior指针，所以插入和删除操作有所不同（引申到头插法也不同）
##### 循环链表
* 循环单链
    * 循环链表与单链表
        * 单链表的最后一个结点时NULL，循环链表最后一个结点时指向头结点
    * 循环链表中没有指针域为NULL的结点，故判其为空的条件不是头结点指针是否为NULL，而是它是否等于头指针
    * 插入删除与单链表几乎一致，若是在表尾操作，则有所不同，因为循环单链式一个环，因此在每一盒位置上的插入和删除操作都是等价的，无需判断是否在表尾
    * 查找可以从任意一点结点开始遍历整个链表，此时只设尾指针，不设头指针，从而使效率更高
* 循环双链表
    * 即通过增加prior，使其既可正向访问，也可以反向访问
##### 静态链表
* 使用数组来描述线性表的链式存储结构，结点有数据域data和指针域next，与前面所说的链表的指针不同，此处的指针指的是结点的相对地址（数组下标），又称游标
* 与顺序表一样，静态链表也要预先分配一块连续的内存空间
* 与顺序表的不同
    * 逻辑上的顺序不与物理上顺序一一对应
    * 插入删除只需要更改指针，不需要移动元素
***
## 栈和队列
* 结构
    * 线性表
        * 操作受限
            * 栈
                * 顺序栈
                * 链栈
                * 共享栈
            * 队列
                * 循环队列
                * 链式队列
                * 双端队列
        * 数组
            * 一纬数组
            * 多维数组：压缩存储、稀疏矩阵
### 栈的定义（stack）
* 定义
    * 只允许在一端进行插入删除操作的线性表
    * 栈顶（top）：允许进行插入删除的那一端
    * 栈底（bottom）：不允许进行插入删除的那一端
    * 空栈：不包含任何元素的空表
* 操作特性
    * 后进先出(LIFO)
* 栈的基本操作
    * 就那些操作，要背会名字会写代码
### 栈的存储方式
#### 顺序存储
* 称为顺序栈；利用一组地址连续的存储到单元存放自栈底到栈顶的数据元素，同时有一个指向当前栈顶元素的指针（top）
* 栈顶指针
    * 初始值S.top=-1
    * 进栈时，若栈不满，先S.top+1,再送值到栈顶元素
    * 出栈时，栈非空，先取出元素，再S.top-1
    * 栈空时，S.top=-1;栈满时，S.top=maxSize-1;栈长：S.top+1
* 评价
    * 顺序栈的入栈操作受到数组上界的约束，当对栈的最大使用空间估计不足时，有可能发生栈上溢，此时应进行出错处理
* 栈的基本运算
    * 就那些运算
* 共享栈
![img](https://s1.ax1x.com/2020/10/13/0fQnde.jpg)
    * 利用栈底位置相对不变的特性，可以让两个顺序栈共享一个一维数组空间，将两个栈的栈底分别设置在共享空间的两端，两个栈顶向共享空间的中间延伸
    * 1号栈为空：S0.top=-1；2号栈为空，S1.top=MaxSize
    * 栈满：S1.top-S0.top=1
    * 进栈：0号栈先加1再赋值，1号栈先减1再赋值
    * 出栈：0号栈先取值再减1，1号栈先取值再加1
    * 评价
        * 更有效的利用存储空间
        * 只有在整个存储空间被占满才发生上溢
        * 存储数据的时间复杂度为O(1)    
#### 链式存储
* 链栈
* 通常采用没有头结点的单链表实现，所有操作在表头进行，Lhead指向栈顶元素
* 评价
    * 便于多个栈共享存储空间和提高其效率，不存在栈满上溢的情况
### 队列的定义（Queue）
* 操作受限的线性表，只允许在一端插入，一端删除
* 插入元素称为入队，进队；删除元素称为出队，离队；
* 操作特性：先进先出(FIFO)
* 队头（Front）：允许删除的一端；队尾（Rear）：允许插入的一端
* 空队列：不含任何元素的空表
* 对其操作
    * 就那些操作（记住名字熟练掌握代码）
    * 栈和队列相对线性表操作受限，不可以随便读取栈和中间的某个元素
### 队列的存储方式
#### 顺序存储
* 其特点上，相对栈，其"底部"不固定
* 分配一块连续的存储单元存放队列中的元素，并附设两个指针：队头指针front指向队头元素，队尾指针rear指向队尾元素的下一个位置（注意题目中的设定，此处与栈顶指针注意区分）。
![img](https://s1.ax1x.com/2020/10/13/0f3hWj.jpg)
* 几种状态
    * 队空：Q.front=Q.rear
    * 队满：Q.rear=MaxSize ? 错误，因为“下底”也在移动，很可能此时只有一个元素，是“假溢出”
    * 进队：进队，Q.rear+1；出队：先出队，然后Q.front+1
* 改进
    * 循环队列
        * 将存储队列元素的表从逻辑上视为一个环，成为循环队列
        * 此时，队空：Q.front=Q.rear
        * 判断队满？注意到当队满时，rear指向其队尾元素的下一个元素，则与front指向同一位置，无法判断是队空还是队满。
            * 牺牲一个单元来区分，解决了上述问题，当满时，rear指向front的前一个元素
                * 队满：(Q.rear+1)%MaxSize==Q.front来判断
                * 队空：Q.rear=Q.front
                * 队长：(Q.rear-Q.front+MaxSize)%MaxSize(负数取余是精髓)
            * 类型中增加表示元素个数的元素怒
                * 队满：Q.size = MaxSize
                * 队空：Q.size = 0
            * 类型中增加tag数据成员
                * tag=0，因删除导致Q.front=Q.rear，则为队空
                * tag=1，因插入导致Q.front=Q.rear，则为队满
#### 链式存储
* 链队列，同时带有头指针和尾指针的单链表；头指针指向队头结点，尾指针指向队尾结点
* 当Q.front == NULL且Q.rear == null,队列为空
* 插入删除与以前的操作无异
* 通常把链式队列设计成带头结点的单链表，这样插入删除操作就同意了
* 评价
    * 适合于数据元素变动特别大的情形
    * 不存在队列满且溢出的问题
    * 一个程序若是要使用多个队列，和使用多个栈一样，最好是使用链式队列，防止存储分配不合理或者“溢出”问题
* 发展
    * 双端队列
        * 两端都可以进行入队和出队操作的队列
        * 分类
            * 输出受限的双端队列
                * 两端均可插，只有一端可以输出
            * 输入受限的双端数列
                * 两端均可输出，只有一端可以插入
### 栈和队列的应用
* 栈在括号匹配中的应用
* 栈在表达式求值中的作用
    * 使用后缀表达式
    * 若为操作数，压入栈中；若为操作符，连续退出栈中两个操作数X和Y，将计算结果重新压入栈中
* 栈在递归中的应用
    * 在一个函数、过程或者数据结构的定义中应用了其自身，则这个函数、过程和数据结构是递归定义的
    * 通常把一个大型问题层层转化为一个与原问题相似的规模较小的问题来求解
    * 递归模型需要满足
        * 递归表达体（递归体）
        * 边界条件（递归出口）
    * 递归的精髓在于是否将原问题转换为属性相同但规模较小的问题
    * 评价
        * 效率低下，但是代码简单，容易理解
* 队列在层序遍历中的应用
    * 层序遍历的方式本来就和队列相似
* 队列在计算机系统中的应用
    * 解决主机与外部设备之间速度不匹配
        * 使用缓冲区，缓冲区所存储的数据本身就是一个队列
    * 解决多用户引起的资源竞争
        * 使用队列来解决（如就绪队列、阻塞队列）
### 数组
* n个相同类型的数据元素构成的有序序列，每个数据元素称为一个数组元素，每个元素在n个线性关系中的序号称为该元素的下标，下标的取值范围称为维界
* 数组与线性表的关系
    * 数组是线性表的推广
    * 一维数组可以视为线性表（线性表的顺序存储是用数组表示的）；二维数组可视为其元素也是定长线性表的线性表
    * **数组一旦被定义，维数和维界就不在改变**，除了初始化和销毁外，**数组只会有存取元素和修改元素的操作**
* 存储结构
    * 地址可计算
    * 对于多维数组，有两种映射方法（分别计算其地址）
        * 按行优先
            * 先存储同行
            * loc(首)+[i*(h<sub>2</sub>+1)+j]*L
        * 按列优先
            * 先存储同列
            * loc(首)+[j*(h<sub>2</sub>+1)+i]*L
### 特殊矩阵的压缩存储
* 压缩存储
    * 为多个值相同的元素只分配一个存储空间，对0元素不分配存储空间，目的是为了节省存储空间
* 对称矩阵
    * 分为三部分，主对角线，上三角、下三角
    * 只需存放对角线和上三角，故若使用二维数组浪费，所以使用大小为n(n+1)/2的一维数组
* 三角矩阵
    * 下三角矩阵是指，上三角区所有元素都为同一常量的矩阵
    * 则需要大小为n(n+1)/2+1的一维数组
* 三对角矩阵（带状矩阵）
    * 将三条对角线上的元素按行优先方式存放在一维数组B中，a<sub>ij</sub>在以为数组中的存放位置k=2*i+j-3
* 稀疏矩阵
    * 当矩阵的元素个数远远大于非零元素的个数时，称为稀疏矩阵
    * 但是非零元素的位置没有规律，所以不仅要存储非零元素，还要存储其位置
    * 结构：（行标，列标，值）
    * 失去了随机存储的特性
***
## 串
* 结构
    * 基本概念：主串，子串，串长
    * 存储结构
        * 定长顺序存储
        * 堆分配存储
        * 块链存储
    * 模式匹配算法
        * 暴力匹配法
        * KMP算法
            * 部分匹配值表
            * next数组
            * next函数的推理过程
        * KMP算法的进一步改进
            * nextval数组
### 串的定义
* 字符串，简称串，非数值处理对象
* S='a<sub>1</sub>a<sub>2</sub>……a<sub>n</sub>'
    * S是串名
    * 引号内是串的值
    * a<sub>i</sub>可以是字母、数字或者其他字符
    * 串中字符的个数n成为串的长度，n=0的串称为空串（由空格组成的是空格串，不是空串，其长度为串中空格字符的长度）
    * 子串：**串中任意连续字符组成的子序列**
        * 其位置以子串的第一个字符在主串中的位置来表示
* 串与线性表
    * 逻辑结构上相似，只是串的数据对象必须为字符集
    * 操作上很大差别，线性表的操作对象是数据元素，串的操作对象是子串
### 串的存储表示
#### 定长顺序存储
* 用一组地址连续的粗不出单元存储串值的字符序列。定长存储中使用定长数组
* 串的实际长度只能小于等于MAXLEN，超过预定义长度的串值将被舍去，称为截断（可以使用动态分配来解决）
* 串的两种表示
    * 用一个额外变量len来存放串的长度
    * 在串值后面加一个不计入串长的结束标记字符"\0"，此时串长为隐含值
#### 堆分配存储
* 仍以一组地址连续的存储单元存放串值
* 但其存储空间是在程序执行过程中动态分配得到的
* C语言中存在一个称之为"堆"的自由存储区，并用malloc(),free()函数来完成动态存储管理。使用malloc()来分配一块实际串长所需的存储空间，若分配成功，返回一个指向起始地址的指针，作为串的基地址；若分配失败，返回NULL
#### 块链存储
* 类似线性表的链式存储，但由于串的特殊性，每个结点可以存放一个字符，也可以存放多个字符，每个结点称之为块，故称为块链结构
![img](https://s1.ax1x.com/2020/10/13/0fRDpj.jpg)
如图所示，若是结点大小为4，即每个结点存放4个字符，最后一个结点占不满时通常用#占位

### 串的基本操作
* 会背名字会写代码
### 串的模式匹配 danger
#### 简单的串模式匹配算法
* 子串的定位操作通常称为串的模式匹配，它求得是子串在主串中的位置
* 暴力破解，依次比较，算法最坏时间复杂度为O(nm)
***
## 树与二叉树
* 树形结构
    * 二叉树
        * 概念
            * 定义、存储结构
        * 操作
            * 三种遍历
            * 线索二叉树
        * 应用
            * 排序二叉树——平衡二叉树
            * 哈夫曼树
    * 树和森林
        * 概念：定义、存储结构
        * 操作
            * 与二叉树的转换
            * 遍历
        * 应用
            * 并查集
### 树的基本概念
#### 概念
* 树是n个结点的有限集，当n=0时，称为空树。在任意一颗非空树中
    1. 有且仅有一个根节点
    2. n>1时，其余结点可以分为m个互不相交的有限级，且每个集合本身又是一棵树，称为根的子树
* 树是递归的数据结构，是一种逻辑结构、分层结构
* 其根节点没有前驱，其余结点仅有一个前驱
* 每个结点最多只和上一层的一个结点有直接关系，且根节点没有直接上层结点，因此n个结点有n-1条边
#### 术语
![img](https://s1.ax1x.com/2020/10/09/0Dl5SH.jpg)
* 结点
    * 祖先，子孙，双亲（仅根节点没有双亲），孩子
    * 兄弟：有相同双亲的结点
    * 分支结点（非终端结点） vs 叶子节点（终端结点）
        * 是否有孩子，即度是否为0
* 结点的度 vs 树的度
    * 结点的度：结点的孩子个数
    * 树的度：max{结点的度}
* 结点的深度、高度、层次
    * 层次：从根开始
    * 深度：自顶向下
    * 高度：自下向上
* 有序树 vs 无序树
    * 有序树：树中各结点从左到右是有次序的，不能互换。若是子结点位置互换，会成为一棵不同的树。否则是无序树
* 路径 vs 路径长度
    * 路径：两个结点所经过的结点序列构成的
    * 路径长度：路径上所经过的边的个数
    * 树中的分支是有向的，即双亲指向孩子，所以树的路径是从上而下的，同一双亲的两个孩子之间不存在路径。
* 森林
    * m个互不相交的树的集合。
    * 把树的根节点去掉就成了森林；把n个树加上一个根节点，森林就变成了树
#### 性质
* 结点数 = 所有结点的度数+1（结点的度数即有几个孩子，所有结点的孩子中不包括根节点，故加1）
* 度为m的树的第i层至多有m<sup>i-1</sup>
* 高度为h的m叉树最多有(1-m<sup>h</sup>)/(1-m)个结点
* 具有n个结点的m叉树最小高度为$\lceil A\rceil$,其中A=log<sub>m</sub>(n(m-1)+1)
### 二叉树
#### 定义
* 在树的基础上增加了两个条件
    * 树中不存在度大于2的结点（即每个结点至多有两棵子树）
    * 子树分左右（即有序树）
    * 即使只有一课子树也要分左右
* 二叉树 vs 度为2的有序树
    * 度为2的有序树至少有三个结点，二叉树可以为空
    * 有序树的左右次序是相对的，即若只有一个孩子，不区分左右；二叉树的左右次数是绝对的，仅有一个孩子也要分左右
#### 二叉树的性质
* 非空二叉树的叶子结点数等于度为2的结点数加1，即n<sub>0</sub>=n<sub>2</sub>+1(利用结点数等于边的条数加1)
* 双亲与子结点序号的关系（序号从1开始）
    * 当i>1,结点i的双亲结点为$\lfloor i/2 \rfloor$,当i为偶数时，其为左孩子，i为奇数时，其为右孩子。
    * 相对，当2i$\leq $n,结点i的左孩子为2i，否则无左孩子
    * 当2i+1$\leq$n,结点i的右孩子为2i+1，否则无右孩子
    * 结点i所在的层次（深度）为$\lfloor A\rfloor$+1,其中A=log<sub>2</sub>i 
* 非空二叉树第k层最多有多少个结点？（和树一样，m=2的特殊情况）
* 高度为h的二叉树至多有多少个结点？（和树一样，m=2的特殊情况）
* 具有n个结点的完全二叉树的高度？（和树一样，m=2的特殊情况）
#### 几种特殊的二叉树
* 满二叉树
    * 一个字满，非叶子结点度数均为2（有两个孩子）
* 完全二叉树
    * i$\leq$$\lfloor n/2\rfloor$,此时结点i为分支结点，否则为叶子结点
    * 叶子结点只会出现在最后两层
    * 度为1的结点，最多只有一个，且其只有左结点，没有右结点
    * 按层序编号时，一旦出现某结点i只有左孩子或者为叶子结点，则大于i的结点均为叶子结点
    * n为奇数时，所有分支结点均有左右孩子，若n为偶数时，编号为n/2的结点只有左孩子，没有右孩子
* 二叉排序树
    * 左子树上所有结点的关键字均小于根结点，右子树上所有结点的关键字均大于关键字。左右子树又各自是一棵二叉排序树
* 平衡二叉树
    * 左子树与右子树的深度之差不超过1
#### 二叉树的存储结构
* 顺序存储结构
    * 用一组地址连续的存储单元依次自上而下，自左向右存储完全二叉树上的结点元素，即将结点i存储在数组的i-1中（**树的结点从1开始计数**）
    * 使用情况
        * 适合完全二叉树和满二叉树，树中结点的序号可以唯一的反映结点之间的逻辑关系（双亲结点和子结点序号关系），既能最大可能的节省空间，也能利用数组元素的下标值确定结点在二叉树中的位置，以及结点之间的关系
        * 但对于一般二叉树，为了能让数组下标反映二叉树中结点之间的逻辑关系，需要补充不存在的空节点，使其能与完全二叉树相对应，然后使用上述存储方法。但是在最坏情况下，高度为h且只有h个结点的单支树却要占据2<sup>h</sup>-1个存储单元。
* 链式存储结构
    * 顺序存储的空间效率低，因此二叉树一般都采用链式存储结构。
    * 一个二叉链表至少包括

    lchild|data|rchild
    --|--|--|
    * **具有n个结点的二叉链表，含有n+1个空链域**。可以使用这些空链域组成另一种链表结构——线索链表
#### 二叉树的遍历
二叉树的遍历：按某条搜索路径访问树中每个结点，每个结点都要被访问，且只被访问一次
* 分为先序遍历NLR、中序遍历LNR、后序遍历LRN
* 其区别只在于访问根节点的次序，所以三个代码只需改动visit(T)的次序，对左右子树的遍历要使用递归(背诵代码)
* 评价
    * 时间复杂度，每个结点只被访问一次，故时间复杂度为O(n)
    * 空间复杂度，因为涉及递归，要使用递归工作栈，工作栈的深度最高位O(n)——单支树
* 使用非递归？->栈？ danger
* 层次遍历
    * 需要借助一个队列，先将二叉树根结点入队，然后出队，访问出队结点，若他有左子树，将左子树根结点入队；若他有右子树，将右子树根结点入队。然后出队，访问出队结点。如此反复，直到队列为空
* 背诵先序、中序、后序遍历的递归和非递归代码，背诵层次遍历的代码
* 由遍历反推二叉树
    * 先序遍历和中序遍历可以唯一的确定一棵二叉树
    * 后序遍历和中序遍历可以唯一的确定一棵二叉树
    * 层序遍历和中序遍历可以唯一的确定一棵二叉树
#### 线索二叉树
* 传统的二叉树仅能体现父子关系，不能直接得到结点在遍历中的前驱或后继。
* n个结点的二叉树为什么有n+1个空链域？
    * 总结点数 n=n<sub>0</sub>+n<sub>1</sub>+n<sub>2</sub>,有总结点n = 边数+1 = 2n<sub>2</sub>+n<sub>1</sub>+1，得n<sub>0</sub>=n<sub>2</sub>+1
    * 又叶子结点有两个空链域，度为1的结点有一个空链域，则总数为2n<sub>0</sub>+n<sub>1</sub>，即n<sub>0</sub>+n<sub>1</sub>+n<sub>2</sub>+1=n+1
    * 结构

    lchild|ltag|data|rtag|rchild
    --|--|--|--|--|
    * 规定，若无左子树，将其指向前驱结点；若无右子树，将其指向后继结点。（此时这个后继结点还没有规定）
    * 如此以来，lchild和rchild中存放的元素就出现了歧义，所以还需ltag和rtag两个标志域

    类别|ltag|rtag|
    --|--|--|
    0|指向左孩子|指向右孩子
    1|指向前驱结点|指向后继结点
    * 其存储结构成为线索链表，其中指向结点前驱和后继的指针称为线索，加上线索的二叉树称为线索二叉树
    * 分类
        * 中序线索二叉树
        * 先序线索二叉树
        * 后序线索二叉树
        * 二叉树的线索化是将二叉链表中的空指针改为指向前驱或指向后继的线索，前驱和后继的信息只有在遍历时才能得到。故其实质就是遍历一次二叉树。其前驱结点为对应的遍历中出现的前驱结点，后继结点为对应遍历序列出现的后继结点
        * 掌握其结构，掌握对应序列的排序方法，画图即可       
### 树、森林
#### 树的存储结构
* 双亲表示法
    ![img](https://s1.ax1x.com/2020/10/10/0ykYAH.jpg)
    * 使用连续的存储空间来存储每个结点，同时在每个结点中增设一个伪指针，指示其双亲结点在数组中的位置
    * 利用了每个结点（根结点除外）只有唯一双亲的性质，可以很快的带每个结点的双亲结点，但求结点的孩子时需要遍历整个结构
    * 树的顺序存储结构 vs 二叉树的顺序存储结构
        * 树的顺序存储结构中：下标代表编号，存储内容代表其双亲结点
        * 二叉树的顺序存储结构中：数组下标既代表了结点的标号，又指示了二叉树中各结点之间的关系。
        * 二叉树可以采用树的顺序存储方式，树不能采用二叉树的顺序存储方式。
* 孩子表示法
    ![img](https://s1.ax1x.com/2020/10/10/0ykeAJ.jpg)
    * 将每个结点的孩子结点都用单链表链接起来形成一个线性结构，则n个结点就有n个孩子链表（叶节点的孩子链表为空）
    * 评价
        * 寻找子女的操作非常简单，寻找双亲的操作需要遍历n个结点中孩子链表指针所指向的n个孩子链表
* 孩子兄弟表示法(二叉树表示法)
    ![img](https://s1.ax1x.com/2020/10/10/0yknhR.jpg)
    * 以二叉链表作为树的存储结构，包括三部分：结点值，指向结点第一个孩子结点的指针，及指向下一个兄弟结点的指针（沿此域可以找到结点的所有兄弟结点）
    * 评价
        * 灵活，能够方便的实现树转换成二叉树的操作，易于查找结点的孩子，但缺点是从当前及诶单查找其双亲结点比较麻烦。
    * 改进
        * 为每个结点增设一个parent域指向其父结点，则查找父结点也很方便
#### 树、森林、二叉树的转换
* 二叉树与树的转换
    * 二叉树和树（孩子兄弟表示法）都可以使用二叉链表作为存储结构，因此二叉链表作为媒介可以导出树和二叉树的对应关系
    * 物理结构上，他们的二叉链表都相同，只是解释不通（也就说，拿到一个二叉链表，不能直接认为是二叉树，还有可能是树的孩子兄弟表示法）
    * 树转换为二叉树
        * 每个结点左指针指向它第一个孩子，右指针指向他在树中的相邻右兄弟（左孩子右兄弟），因为根节点没有兄弟，所以转换成的二叉树没有右子树
        * 画法：
            1. 在兄弟结点间加一条线
            2. 对每个结点，只保留它与第一个孩子结点的连线
            3. 以树根为轴，顺时针旋转45度
    * 森林转换成二叉树
        1. 将每一棵树转化成二叉树
        2. 将第二棵树插入第一棵树的右子树，以此类推
#### 树和森林的遍历
* 树的遍历
    * 先根遍历
        * 与对应二叉树的先序遍历序列相同
    * **后根遍历**
        * **与对应二叉树的中序遍历序列相同**
    * 层序遍历
        * 与二叉树思想相同
* 森林的遍历
    * 先序遍历森林
        1. 访问第一棵树的根节点
        2. 先序遍历第一棵树中根结点的子树森林
        3. 先序遍历剩余的树
    * 中序遍历森林
        1. 中序遍历森林中第一棵树的根节点的子树森林
        2. 访问第一棵树的根节点（相同于将子树遍历完再遍历根节点）
        3. 中序遍历剩余的树
### 树与二叉树的应用
#### 二叉排序树（二叉查找树）（BST）
* 其满足
    * 若左子树非空，则左子树上所有结点的值均小于根结点的值
    * 若右子树非空，则右子树上所有结点的值均大于根结点的值
#### 平衡二叉树
#### 哈夫曼树和哈夫曼编码
***
## 图
* 结构
    * 图的定义
    * 图结构的存储
        * 邻接矩阵法
        * 邻接表法
        * 邻接多重表
        * 十字链表
    * 图的遍历
        * 深度优先遍历
        * 广度优先遍历
    * 图的相关应用
        * 最小生成树：Prim，Kruskal
        * 最短路径：Dijkstra，Floyd
        * 拓扑排序：AOV
        * 关键路径：AOE
### 图的基本概念
### 图的存储及基本操作
### 图的遍历
* 图的遍历是从图中某一顶点出发，按照某种搜索方法沿着图中的边对图中所有顶点访问一次，且仅访问一次。
* 树是一种特殊的图，树的遍历时特殊的图遍历；图遍历比树遍历复杂的多，因为图的任一顶点都可能与其余顶点相连。
* 为避免同一顶点被访问多次，要使用visited[]来标记顶点是否被访问过
#### 广度优先算法BFS
* 类似二叉树的层序遍历
* 以顶点v为起点，由近至远的依次访问和v有路径相通且路径长度为1,2，...的顶点；是一种分层查找过程，每向前走一步可能访问一批顶点，不像深度优先算法有回退的情况，所以不是递归算法。
* 为实现逐层访问，算法必须借助一个辅助队列，以记忆正在访问的顶点的下一层顶点。
* 动手模拟(理解过程)
![img](https://s1.ax1x.com/2020/10/12/02TuAf.jpg)
    访问次序:abcdefgh
* 评价
    * 空间复杂度：无论采取哪种存储方式，都需要一个辅助队列，且每个顶点入队一次，最坏情况下，空间复杂度O(|V|)
    * 时间复杂度
        * 邻接表法
            * 每个顶点均需搜索一次，且每条边至少访问一次，时间复杂度为O(|V|+|E|)
        * 邻接矩阵
            * 查找每个顶点的邻接点所需的时间O(|V|)，故算法的总时间复杂度为O(|V|<sup>2</sup>)
* 应用
    * 求解单源最短路径问题
    * 广度优先生成树
        * 按照广度遍历形成的遍历树
        * 邻接矩阵唯一，生成树唯一；但邻接表不唯一，生成树不唯一
#### 深度优先算法DFS
* 类似于树的先序遍历，尽可能深的搜索一个图
* 基于邻接矩阵遍历得到的深度广度优先序列唯一，基于邻接表不唯一
* 评价
    * 空间复杂度
        * 需要借助递归工作栈，时间复杂度为O(|V|)
    * 时间复杂度
        * 遍历图的实质是对每个顶点查找其邻接点的过程，耗费的时间取决于所用存储结构
        * 邻接表
            * O(|V|+|E|)
        * 邻接矩阵
            * O(|V|<sup>2</sup>)
* 应用
    * 深度优先生成树和生成森林
        * 连通图——生成树
        * 非连通图——生成森林
#### 图的遍历与其连通性
* 无向图，若连通，则一次遍历可以访问所有顶点
* 有向图，只有初始点到所有顶点都有路径，才能访问到所有顶点
### 图的应用
* 最小生成树
    * 一个连通图的生成树包含图的所有顶点，并且只含尽可能少的边。若砍去其一条边，则变成非连通图；若增加一条边，则会形成回路
    * 最小生成树是权值之和最小的生成树
    * 最小生成树的性质
        * 不唯一；但当各边权值不等时唯一
        * 若无向连通图G的边数等于顶点数减1，则最小生成就是他本身
        * 树不唯一，但权值之和唯一，总是最小
    * 算法实现
        * 思想：当T未形成一棵生成树时，找到一条最小代价边，使其加入T不会产生回路
        * 两种具体算法（均基于贪心算法：不断寻找局部最优解）
            * PRIM算法
                * 任取一顶点加入集合，选择与当前顶点最近的顶点和相应的边加入T，每次操作顶点数和边数都加1，主义不能形成环路，当所有顶点都加入时，即使最小生成树，此时有n个顶点和n-1条边
                * 评价
                    * 时间上仅与顶点有关，与边无关，O(|V|<sup>2</sup>),故适合边稠密的图
                    * 有其他方法可以改进其时间复杂度，但是增加了实现复杂性    
            * Kruskal
                * PRIM从任一顶点扩展，Kruskal按权值递增的次数选择合适的边
                * 将顶点全部填入，每次选择权值最小的边，若形成回路则舍弃，共需要选中n-1条边
                * 评价
                    * 用堆来存放边的集合，每次选择权值最小的边只需O(log|E|),可以使用并查集的数据结构描述T，从而构造T的时间为复杂度为O(|E|log|E|)
                    * 适合顶点多，边稀疏的图
what is 并查集？
* 最短路径
    * 广度优先搜索查找最短路径只是对无权图而言的，此处要考虑权值之和最小
    * 都依赖于一种性质：两点之间的最短路径也包含了路径上其他顶点间的最短路径
    * 分类
        * Dijkstra（单源）
            * 权值不可以为负
            * 基于贪心算法
        * Floyd（每个顶点）
* 有向无环图
    * 若一个有向图不存在环，则称为有向无环图
    * 有向无环图是描述含有公共子式的表达式的有效工具
    * 例如((a+b)x(bx(c+d))+(c+d)xe)x((c+d)xe)
        * 其中相同的子表达式在二叉树中也会重复出现，若使用有向无环图，则可以实现对相同子式的共享，从而节省存储空间
* 拓扑排序
    * AOV网：用DAG（有向无环图）表示的一种活动间的前后关系（用顶点来表示活动的网络）(activities on vertices)
    * 拓扑排序
        * 当DAG满足下列条件，被称为AOV网
            * 每个顶点都出现，且只出现一次
            * 顶点A在序列中排在顶点B的前面，则在图中不存在顶点B到顶点A的路径
            * 拓扑排序是对有向无环图的一种排序，他使得若存在一条从顶点A到顶点B的路径，则排序中顶点B出现在顶点A的后面。
            * 每个AOV网都有一个或多个拓扑排序数列
        * 对AOV网进行拓扑排序的方法
            1. 选择一个没有前驱的顶点输出        
            2. 从网中删除该顶点和所有以他为起点的有向边
            3. 重复1和2，直到当前AOV网为空或者当前网中不存在无前驱的顶点位置，后一种情况说明有向图必然有环
        * 评价
            * 因为每输出一个结点还要删除对应的边，故时间复杂度为O(|V|+|E|)
        * 若是按照拓扑排序的结果重新编号，生成的AOV网的新的邻接矩阵，这种矩阵可以是三角矩阵；对于一般图而言，若其邻接矩阵为三角矩阵，则存在拓扑排序；反之不一定   
* 关键路径
    * 在带权有向图中，以顶点来表示事件，以有向边来表示活动，边上的权值表示活动的开销，称之用边来表示活动的网络AOE网(activity on edge network)
    * AOE和AOV都是有向无环图，不同之处在于边和顶点的含义不同，AOE网的边有权值，AOV的边仅表示前后关系
    * AOE网
        * 性质
            * 只有在某顶点代表的事情发生后，从该顶点出发的各条有向边所代表的活动才能开始
            * 只有进入某顶点的各有向边所代表的活动都已结束时，该顶点所代表的事情才能开始。
        * 入度为0的点，开始顶点（源点）；出度为0的点，结束顶点（汇点）
        * AOE网上有些活动可以并行进行，源点到汇点的有向路径可能有多条，完成不同路径上的活动所需要的时间不同，但是只有所有路径上的活动都已完成，整个工程才算结束。
        * 其中，从源点到汇点的所有路径中，具有最大路径长度的路径成为关键路径，在关键路径上的活动成为关键活动。
        * 完成整个工程的最短时间就是关键路径的程度，即关键路径上各活动花费开销的总和。
        * 计算
            * 事件最早完成时间
            * 事件最迟发生时间
            * 活动最早开始时间
            * 活动最迟结束时间
            * 活动可拖延时间=活动最迟-活动最早 danger
    
***
## 查找
### 查找的基本概念
* 查找表（查找结构）
    * 用于查找的数据集合成为查找表
    * 对其有4种操作
        * 1.查找某数据元素是否在表内
        * 2.检索满足条件的数据元素的各种属性
        * 3.插入
        * 4.删除
* 静态查找表 vs 动态查找表
    * 静态查找表：只执行1.2操作，不修改查找表
    * 动态查找表：需要动态的插入或删除的查找表
    * 其中适合静态查找的有顺序查找，折半查找，散列查找；适合动态查找的有二叉排序树查找，散列查找
* 知识结构
    * 线性结构
        * 顺序查找
        * 折半查找
        * 分块查找
    * 树形结构
        * 二叉排序树
        * 二叉平衡树
        * B树，B+树
    * 散列结构
        * 散列表
            * 性能分析
            * 冲突处理
    * 效率指标
        * 平均查找长度
            * 查找成功
            * 查找失败
### 查找的方法
#### 顺序查找法
##### 一般无序线性表
* 引入哨兵，和return i配合，不用担心数组越界。
* 平均查找长度
    * 成功 （n+1）/2
    * 失败 n+1
* 改进
    * 若每个记录的查找概率并不相等，且实现知道每个记录的查找概念，则按照概率排序，概率大的先查找，可以降低查找成功的平均查找长度
* 评价
    * 缺：当n较大，平均查找长度大
    * 优：对数据存储无要求，使用顺序存储和链式存储均可
        * 特殊
            * 而线性链表只能使用顺序查找
##### 有序表的顺序查找
* 相对于一般无序线性表，查找成功的平均查找长度不变；查找失败时，不一定要比较完全部结点，故查找失败的平均查找长度缩短，可以用树状图表示，为（1+2+3+4+5+...+n+n）/(n+1)
#### 折半查找法（二分查找）
* 仅适用于有序顺序表（一要有序，二要顺序存储，而非链式存储）
* 每次范围缩减一半，过程相当于一个判定树，且判定树的是一颗平衡二叉树，元素为n时，树高为log<sub>2</sub>(n+1)
* 平均查找长度
    * 故查找成功的平均查找长度不超过树的高度ASL=$\frac{1}{n}$(1x1+2x2+...hx2<sup>h-1</sup>)= $\frac{n+1}{n}$log<sub>2</sub>(n+1)-1=log<sub>2</sub>(n+1)-1
    * 查找失败（查找成功和查找不成功在有限个数的情况下，可以画树形图进行计算）
* 评价
    * 优：时间复杂度为O(log<sub>2</sub>n),平均情况下笔顺序查找效率高
    * 缺：需要满足顺序存储（随机存取），仅用于关键字有序的情况下
#### 分块查找法
* 分块：块间有顺序，块内无顺序；故块间折半或顺序查找，块内顺序查找
* 平均查找长度
    * 分为两部分，块间查找和块内查找（设均为分为b块，每块s个记录）
    * 均采用顺序查找时
        * ASL = L<sub>I</sub> + L<sub>S</sub>= $\frac{b+1}{2}$+$\frac{s
        +1}{2}$
        * 此时若s=$\sqrt{n}$，取得平均查找长度最小$\sqrt{n}$+1
    * 组间采用折半查找，组内采用顺序查找
        * ASL = L<sub>I</sub> + L<sub>S</sub>=log<sub>2</sub>(b+1)+$\frac{s
        +1}{2}$
#### B树及其基本操作，B<sup>+</sup>树的基本概念
##### B树（多路平衡查找树）
* B树中所有节点的孩子个数（关键字个数+1）的最大值成为B树的阶.
![img](https://s1.ax1x.com/2020/10/07/0af3OP.jpg)
* 据图理解
    * 最大关键字个数是4，最大孩子个数是5，这是一个5阶B树，
    * 如果根节点没有关键字，就没有B树，此时B树为空；若是有关键字，至少有两个子树（因为孩子个数=关键字个数+1）
    * 除根节点以外所有非终端节点至少有[m/2]棵子树，即[5/2]=3棵子树
    * 结点中的关键字从左到右单调递增
    * 叶节点均在第四层，代表查找失败的位置；不带任何信息，实际这些点不存在。
* B树的高度（磁盘存取次数）
    * B树大部分操作所需的磁盘存取次数和B树的高度程正波
    * 高度不包括最后不带任何信息的那一层
    * 以n个关键字，高度为h，阶数为m的B树为例
        * 每个结点最多有m棵子树，m-1个关键字，每一层子树的数量最多是上一层的m倍，则有
            * n$\leq $(m-1)(1+m+...+m<sup>h-1</sup>)=m<sup>h</sup>-1
            * 即 h$\geq$log<sub>m</sub>(n+1)
        * 若想求h的最大值，就要让每个结点包含的关键字最少
            * 第一层至少1个结点，第二层至少2个结点，而除根节点外的非终端结点至少有[m/2]棵子树，第三层为2[m/2],第h+1层(实际不存在，不带信息)至少2[m/2]<sup>h-1</sup>，有n+1$\geq$2[m/2]<sup>h-1</sup>
            * 即 h$\leq$log<sub>$\frac{m}{2}$</sub>($\frac{n+1}{2}$)+1
* B树的查找
    * 包含两个基本操作
        * 在B树内查找结点（磁盘上进行）
        * 在结点内查找关键字（内存中进行）
            * 即在找到目标结点后，先将结点信息读入内存，在内存中采用顺序查找或者折半查找
![img](https://s1.ax1x.com/2020/10/07/0af3OP.jpg)
        * 根据图说明查找过程（查找关键字为42）
            * 将根节点读入内存，查找发现42>22
            * 读入右子树，36<42<65
            * 读入中间子树，在该结点中查到42，查找成功
            *（若查找到h+1层，即叶节点，即查找失败，叶节点对应指针为空指针）
* B树的插入（因为关键字有上限，涉及拆分）
    * 相较二叉查找树复杂。B树在查找到插入位置，不能简单将其添加到终端结点，否则可能导致整棵树不再满足B树的定义
        * 定位
            * 按照查找算法，插入最底层非页结点
        * 插入
            * 若插入后关键字个数小于m，直接插入
            * 若大于等于m，则必须对结点进行分裂
            * 插入过程
![img](https://s1.ax1x.com/2020/10/07/0aIxPS.jpg)
                * 分裂，将左右分为两个结点，中间结点上移至上一层结点；若此时上一层结点关键字也出现超出现象，继续上移，继续这种操作，直到传到根节点，导致B树高度加1
* B树的删除（因为关键字有下限，涉及合并）**danger**
    * 关键字个数要$\geq$ [m/2]-1
    * 删除操作
        * 当删除结点为非终端节点，直接用其前驱或者后继取代,再将前驱或后继中对应的关键字删除即可（做法简单，不多讨论）
        ![img](https://s1.ax1x.com/2020/10/07/0dCVnP.jpg)
        * 当删除结点为终端结点（最底层非叶结点）
            * 直接删除
                * 当删除关键字所在结点$\geq$[m/2],可以直接删去
            * 兄弟够借
                * 父子换位法
            ![img](https://s1.ax1x.com/2020/10/07/0dcgeS.jpg)
            * 兄弟不够借
                * 兄弟与双亲结点中某个关键字合并，若双亲结点不满足B树条件，继续向上调整
            ![img](https://s1.ax1x.com/2020/10/07/0dc5zq.jpg)
##### B<sup>+</sup>树
* 应数据库而生的B树的变形树
* B树 vs B<sup>+</sup>树

类型|B树|B<sup>+</sup>树|
--|--|--|
关键点和子树|n个关键点n+1个子树|n个关键点n个子树|
每个结点关键字范围|$\lceil m/2 \rceil$-1,m-1(根结点[1,m-1])|$\lceil m/2 \rceil$,m|
结点功能|叶节点指针为空|叶节点包含信息，非叶节点仅起索引作用，对应子树的最大关键字|
关键字是否重复|不重复|重复
![img](https://s1.ax1x.com/2020/10/07/0d2TVU.jpg)
* 此图为4阶B<sup>+</sup>树，最多有m个子树（B树中是最多有m个孩子）；
* 通常有两个指针，一个指向根节点，一个指向关键字最小的叶结点；对应两种运算，一种从最小关键字开始的顺序查找，一种从根节点开始多路查找。
* B<sup>+</sup>树的查找、插入、删除和B树类似，只是在查找过程中，非叶结点上的关键字值等于定值时并不终止，而是继续向下查找，知道叶结点该关键字为止。所以无论成功与否，每次查找都是一条根结点到叶结点的路径。
#### 散列表
* 前面的查找方法中，记录在表中的位置与关键字之间不存在确定关系，查找纪律需要经过一系列的关键字的比较，故查找效率取决于比较的次数。
* 而散列表是根据关键字直接进行访问的数据结构。散列表建立了关键字与存储地址之间的一种直接映射关系。故查找的时间复杂度为O(1),即与表中个数无关。
* 散列函数
    * 一个把查找表的关键字映射成该关键字地址的函数，记为Hash(Key)=Addr
    * 散列函数可能会把两个或两个以上的不同关键字映射到同一地址——冲突
    * 这些发生碰撞的不同关键字称为同义词
    * 一方面，好的散列函数能尽量减少冲突；另一方面，冲突不可避免，要设计好的处理冲突的方法
* 散列函数的构造方法
    * 直接定址法
        * 线性函数
        * Hash(key)=key 或 Hash(key) = a*key+b
        * 不会产生冲突，适合于关键字分布基本连续的情况，若分布不连续，空位较多，会造成存储空间的浪费
    * 除留余数法
        * 假设散列表表长m，取一个最大的且$\leq$m的质数
        * Hash(key)=key%p
        * 关键在于选好p，使得每个关键字通过函数转换后等概率映射到散列空间上的任一地址，减少冲突的可能性（常用）
    * 数字分析法
        * r进制数，取在某些位上分布较为平均的位作为散列地址
        * 1100101 1101010 0101101 0110010
        * 则中间三位分布比较平均，分别为001 010 011 100，作为散列地址
        * 但是若更换关键字，需要重新构造散列函数
    * 平方取中法
        * 取关键字平方值的中间几位作为散列地址，具体取多少位视情况而定
        * 适合于关键字的每位取值都不够均匀，或均小于散列地址所需位数
    * 总评
        * 目标
            * 减少冲突发生的概率
        * 好坏
            * 根据关键字集合而定
* 处理冲突的方法
    * 开放地址法
        * 存放新表项的空闲地址既向其同义词表项开放，也向其非同义词表项开放
        * 公式
            * H<sub>i</sub>=(H(key)+d<sub>i</sub>)%m
            * 其中i属于[1,m-1]
            * 所以当其中的**d<sub>i</sub>**取定后，处理方法就确立了，取d<sub>i</sub>的几种方法
                * 线性探测法
                    * d<sub>i</sub>取0,1,2,...m-1
                    * 冲突发生时，顺序查看表中下一个单元（探测到m-1时，下一位是0），直到找到一个空闲单元或查遍全表
                    * 但会造成大量元素在相邻散列地址上“聚集”（“堆积”），大大降低了查找效率
                * 平方探测法(二次探索法)
                    * d<sub>i</sub>取0<sup>2</sup>,1<sup>2</sup>,-1<sup>2</sup>,...,k<sup>2</sup>,-k<sup>2</sup>,其中k$\geq$m/2
                    * 散列表的长度必须是一个可以表示成4k+3的素数，又称二次探索法
                    * 可以避免“堆积”，但是不能探测到散列表上所有单元，但至少可以探测到一半
                * 再散列法(双散列法)
                    * d<sub>i</sub>=Hash<sub>2</sub>(key)
                    * H<sub>i</sub>=(H(key)+i*Hash<sub>2</sub>(key))%m
                * 伪随机数列法
                    * 当d<sub>i</sub>为伪随机数序列时，称为伪随机序列法
                * 总评
                    * 在开放地址的情形下，不能随便物理删除表中已有元素，否则会截断其他具有相同散列四肢的元素的查找地址，可以使用逻辑删除，做个删除标记，但不删除。副作用：执行多次删除后，表面上散列表很满，实际很多位置未利用，因此需要定期维护，将删除标记的元素物理删除。
    * 拉链法（链接法，chaining）
        * 直接将同义词存储在用一个线性链表中，来避免非同义词发生冲突。
        * 这些线性链表由其散列地址唯一标识
        * 拉链法适合需要经常插入和删除的情况
        ![img](https://s1.ax1x.com/2020/10/08/0whqVP.th.jpg)
    * 总评
        * 查找过程
            * Addr = Hash(key)
            * 检查Addr上是否有记录，无记录则查找失败；有记录进行，比较，若相同，查找成功，否则执行下一步
            * 用给定的冲突处理方法计算“下一个散列地址”，将Addr置为此地址，执行上一步
        * 虽然散列表在关键字和记录之间建立了直接映象，但是由于“冲突”的产生，仍需一个给定值和关键字比较的过程，仍需以平均查找长度作为衡量其查找效率的度量（根据实际情况手动就算）
        * 查找效率的取决因素
            * 散列函数、处理冲突的方法、装填因子
            * 装填因子 = 表中记录数n/散列表长度m
            * 散列表的平均查找长度依赖于**装填因子**，而非m，n，装填因子越大，装填的纪录越满，发生冲突的概率越大。
### 查找算法的分析及应用
***
## 排序
### 基本概念
* 重新排列表中的元素，使得其关键字有序
* 算法的稳定性
    * 关键字相同的两个元素，经过排序后相对顺序始终不变
    * 只是对算法性质的描述，不反映其优劣，性能取决于时空负责度
    * 仅需举出反例说明其不稳定即可
* 内部排序 vs 外部排序
    * 元素是否全部存放在内存
* 一般都需要经过比较和移动，其中**基数排序不基于比较**
### 内部排序
#### 插入排序  
>基本思想：每次将一个待排序的记录按其关键字大小插入到前面已排序号的子序列中。
* 直接插入排序

有序序列L[1,...,i-1]|L(i)|无序序列L(i+1...n)|
--|--|--|
    
三步走：
1. 查询L(i)的插入位置k
2. 保存L(i)为m,将k~i-1所有元素向后移一位
3. 将m放入位置k

    * 评价
        * 空间复杂度，仅需使用一个哨兵，与n大小无关，为O(1)
        * 时间复杂度
            * 最优：n(n-1)/2（待定）
            * 最差：n-1
            * 平均：O(n<sup>2</sup>)
        * 稳定性：稳定
        * 适用性：顺序存储和链式存储（大部分排序算法都仅适用于顺序存储的线性表）
* 折半插入排序
    * 可以看出直接插入分为了查找和移动两个部分，而其中查找是对有序表的查找，可以使用折半查找的方法来降低查找（比较）次数，为O(nlog<sub>2</sub>n),比较次数与初始状态无关，仅与n的大小有关
    * 总体时间复杂度仍为O(n<sup>2</sup>)
    * 稳定排序
    * 适用于数据量不是很大的排序表
* 希尔排序（shell sort）（缩小增量排序）
    * 直接插入排序时间复杂度为O(n<sup>2</sup>),但若是排序为“正序时”，时间复杂度可提高至O(n),针对这点，希尔排序对其进行了改进。
    * 过程
        * 每隔d个步长组成一张子表，对子表进行直接插入排序
        * 缩短步长，重复上一步操作
        * 当d=0时，停止
    * 一般d<sub>1</sub>=n/2,d<sub>i+1</sub>=$\lfloor di/2 \rfloor$
    * 评价
        * 空间：仅使用了常数个辅助单元，空间复杂度为O(1)
        * 时间：依赖于增量序列函数，数学上尚未解决；时间负责度约为O（n<sup>1.3</sup>),在最坏情况下希尔排序的时间复杂度为O(n<sup>2</sup>)
        * 稳定性：不稳定
        * 适用性：仅适用于线性表为顺序存储的情况
#### 交换排序
* 冒泡排序（bubble sort）
    * 从后往前两两比较相邻元素的值，若为逆序，则交换，直到序列比较完，为第一趟排序，最多进行n-1次排序就结束。若是其中出现了某一趟，顺序没有发生变化，则表明表已有序，冒泡排序结束。
    * 评价
        * 空间复杂度：O(1)
        * 时间复杂度：最好O(n),最差O(n<sup>2</sup>),平均也为O(n<sup>2</sup>)
        * 稳定性：稳定
        * 产生的子序列全局有序，每一趟排序都会将一个元素放到其最终位置上（与直接插入不同）
* 快速排序
    * 基于分治的
    * 手动模拟其递归过程
    * 每一趟排序都会有一个元素放到其最终位置上
    * 使用递归
    * 评价
        * 空间复杂度，由于快速排序是递归的，所以需要一个递归工作栈，**其容量和递归调用的最大深度一致**，最好情况为O(log<sub>2</sub>n)，最差情况为O(n),平均情况为O(log<sub>2</sub>n)
        * 时间效率，运行时间与划分是否对称有关，最坏情况两个区域分别包含n-1个元素和0个元素，这种不对称性若是发生在每层递归上（即基本有序或基本逆序），最坏情况下的时间复杂度为O(n<sup>2</sup>)，最好情况下为O(nlog<sub>2<sub>n)
            * 提高效率的方法
                * 选取一个尽可能将数据中分的枢轴元素，如取头、尾、中间三值的平均值
                * 随机地从表中选取枢轴元素，这样使得最坏情况几乎不会发生
        * 是所有内部排序算法中平均性能最优的排序算法
        * 稳定性：不稳定
#### 选择排序
基本想法：每一趟（第i趟）在后面的n-i+1个待排序元素中选取关键字最小的元素，作为有序子序列的第i个元素，直到n-1趟做完，待排序元素只剩下一个，就不用选了。
* 简单选择排序
    * 评价
        * 空间复杂度，O(1)
        * 时间复杂度，O(n<sup>2</sup>)
        * 稳定性，在第i趟找到最小元素，与第i个元素交换，可能会导致含有相同关键字元素的相对位置发生改变
* 堆排序
    * 完全二叉树
    * 大根堆 vs 小根堆
        * 大根堆，双亲结点大于子节点，则最大元素在根节点，L(i)$\geq$L(2i)且L(i)$\geq$L(2i+1)
    * 堆排序的过程（以大根堆为例）
        * 输出堆顶元素（最大值）
        * 将堆底元素送入堆顶，此时已不满足大顶堆的性质，调整使其满足大顶堆，重复上一步，直到仅剩一个元素为止。
    * 由排序过程，引出两个问题，1.堆的初始化，2.输出堆顶后剩余元素如何调整成堆
        * 堆的初始化（动手模拟）
            * **自下而上**逐步调整每个双亲结点与其孩子的关系，交换后可能会破坏下一级的堆，需要采用之前的方法继续调整（如第五步）
        ![img](https://s1.ax1x.com/2020/10/08/00LlAH.jpg)
        * 堆的调整
            * 将堆的最后一个元素和堆顶元素交换，**自上而下**逐步调整每个双亲结点与其孩子的关系
            ![img](https://s1.ax1x.com/2020/10/08/00OEVg.jpg)
    * 堆的插入
        * 将新结点放在堆的末端，然后对堆执行向上调整
    * 评价
        * 调整时间和树的高度有关，在建立n个元素的堆时，关键字最多比较时间不超过4n，时间复杂度为O(n),这说明可以在线性时间将一个无序数组组建成一个堆。
        * 使用情况：适合关键字较多的情况（n>1000）
        * 空间效率：O(1)
        * 时间效率：建堆O(n),调整时间，每次调整的复杂度为O(h),故在最好、最坏和平均情况下，堆排序的复杂度为O(nlog<sub>2</sub>n)
        * 稳定性：不稳定
#### 二路归并排序（merge sort）
* 归并：将两个或两个以上的有序表组合成一个新的有序表
* 假定待排序的表含有n个记录，则可将其视为n个有序的子表，每个子表的长度为1，然后两两归并，得到$\lceil n/2\rceil$个长度为2或1的有序表，继续两两归并，如此重复，直到合并成一个长度为n的有序表为止
![img](https://s1.ax1x.com/2020/10/08/00vURs.jpg)
* 一趟归并算法,调用$\lceil n/2h \rceil$次merge(),将前后相邻且长度为h的有序段两两合并，得到前后相邻、长度为2h的有序段，整个归并排序需要进行$\lceil  A \rceil$趟,其中A=log<sub>2</sub>n，递归形式的二路归并算法是基于分治的；
* 其中merge()的功能，将前后相邻的两个有序表归并成一个有序表，设两段A[low...mid]、A[mid+1...high]存在在同一顺序表的相邻位置，先将他们复制到辅助数组B中（空间复杂度的来源），每次从对应B中的两个段取出一条记录进行关键字的比较，将较小者放入A，当数组B中有一段下标超出其对应的表长（即该段中所有元素都已复制到A中），将另一段的剩余部分直接复制到A中。
* 评价
    * 空间复杂度：辅助单元刚好n个单元，复杂度O(n)
    * 时间效率：每趟归并的时间复杂度为O(n),共需进行$\lceil  A \rceil$趟,其中A=log<sub>2</sub>n，所以算法的时间复杂度为O(nlog<sub>2</sub>n)
    * 稳定性：稳定（相邻元素比较则稳定，全局比较则不稳定）
#### 基数排序
* 不急于比较和移动，而是基于关键字各位的大小，借助多关键字排序的思想对单逻辑关键字进行排序
* 分类
    * 最高位优先（MSD）
    * 最低位优先（LSD）
* 按照各位的数值进行多次分配与收集
* 评价
    * 空间效率，辅助空间每次需要r个（r个队列，实际中进制位数），可以重复使用，故为O(r)
    * 时间效率，需要进行d趟分配与收集（所给数集的位数），一趟分配需要O(n),一趟收集需要O(r)，故时间效率为O(d(n+r))，与初始状态无关
    * 稳定性：稳定
### 外部排序
* 外部排序是指待排序文件较大，内存一次放不下，需存放在外存的文件的排序。
* 为减少平衡归并中外存读写次数所采取的的方法：增加归并路数和减少归并段个数
    * 增大归并路数：败者树
    * 减少归并段个数：置换-选择排序
* 文件通常按块存储在磁盘上的，操作系统也是按块对磁盘上的信息进行读写的。因为磁盘读/写的机械动作的所需的时间远远超过内存运算的时间，所以在外部排序过程中时间代价主要考虑**访问磁盘的次数**。
* 常采用**归并排序**
    1. 根据内存缓冲区大小，将外存文件进行分割，依次读入内存并利用内部排序进行排序，并将排序后的有序数列重新写回外存，称这些有序数列为**归并段**或**顺串**
    2. 对这些归并段进行逐趟归并，使归并段（有序子文件）逐渐由小到大，直至得到整个有序文件为止
### 各种排序算法的比较和应用
* 小规模排序（n<10000）
    * 直接插入排序、冒泡排序、简单选择排序是基本的排序方法，主要用于元素个数不是很大的情况（n<10000）的情形
        * 其中直接插入排序和冒泡排序与待排序元素的初始排列有关
        * 简单算法与待排序元素初始状态无关，但不稳定
* 中等规模排序（n<=1000）
    * 希尔排序中，记录的总比较数和总移动次数比直接插入排序时少的多，特别是n越大时越明显，且代码简单，基本不需要什么额外的内存,但不稳定
* 大型规模（n值很大）
    * 采用快排、堆排序、归并排序、基数排序
    * 其中快排和堆排序不稳定，归并排序和基数排序稳定
        * 快排
            * 最通用的高效内部排序算法，平均情况下的时间复杂度为O(nlog<sub>2</sub>n),辅助空间为一个树形栈，与树的高度有关，平均为O(log<sub>2</sub>n)。但是存在退化情况，若是元素序列已经有序时，时间复杂度最高可以达到O(n<sup>2</sup>),空间复杂度最高可以达到O(n).
        * 堆排序
            * 高效排序算法，时间复杂度为O(nlog<sub>2</sub>n),且没有什么最坏情况导致其明显变慢，并且基本上不需要额外的控件，但是堆排序不太可能提供比快速排序更好的平均性能。
        * 基数排序
            * 虽然具有线性增长的时间复杂度，但实际上时间开销并不比快排小很多，且因为其基于关键字抽取算法，受到操作系统和排序元素的影响，适应性远不如普通的进行比较和交换操作的排序算法。
* 混合使用
    * 混合算法充分发挥不同算法各自的优势
***


translate into
turn the cornor