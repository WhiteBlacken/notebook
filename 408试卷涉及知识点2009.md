# 408试卷薄弱知识点
## 要求
* 每日背诵，不留缺陷
* 定位准确，扩展详细，背诵熟练
## 无向连通图
![img](https://s1.ax1x.com/2020/10/15/0ooNBF.jpg)
### 解答
* 无向图；无向图的度等于边数的二倍，故一定是偶数，A正确
* 无向连通图的边数大于等于n-1，此时为极小连通子图，不是大于，B错误
* 至少有一个顶点的度数为1，若是只有一个点，没有边，也是连通图，C错误
### 知识点背诵
* 数据结构-图-图的定义
* 顶点的度
    * 无向图：依附于该顶点的边的条数
        * 全部顶点的度等于边数的两倍
    * 有向图：进一步分为初度和入度
        * 初度等于入度等于边的条数
* 连通
    * 无向图
        * 任意两个顶点都是连通的，则称此图为连通图，否则为非连通图
        * 极小连通子图
            * 保证每两个顶点间都连通，且边数最少，边数为n-1，那么此时度数为2
            * 如果一个n个顶点的图，边数不足n-1，那么必定是非连通图
            * 用于生成树
        * 极大连通子图
            * 连通分量
            * 要求包含该连通子图包含其所有的边
            * 连通图的极大连通子图是它自己
            * 非连通图的极大连通分量有多个（互不相交）
            ![img](https://s1.ax1x.com/2020/10/15/0o7GeU.jpg)
            * 如图所示，不连通的图G，分为了三个连通分量
    * 有向图
        * 强连通图
            * 任意两个顶点间都有正反两条路径
        * 强连通分量
            * 极大连通分量（动手画）
    * 无向图里讨论连通性，有向图里只讨论强连通性
## 森林转化为二叉树
![img](https://s1.ax1x.com/2020/10/15/0oHFh9.jpg)
### 解答
### 知识点背诵
* 数据结构-树-树、森林、二叉树的转换
## C语言类型转换
![img](https://s1.ax1x.com/2020/10/15/0oHI3R.jpg)
### 解答
* x为int类型，占4B，32位，即8位16进制。数值位0111 1111，符号位全0,；C语言数据在主存中以补码存储，此为正数，故不变
* y为short类型，2B，16位，即4位16进制。数值位1001，符号位全1.补码为数值位取反加1位0111，故16进制存储为FFF7H
* z的值为118，int+short=int，类型为int类型。数值位为0111 0110，符号位全0，补码不变，故存储为16进制为00000076H
### 知识点背诵
* 组合原理-数据的表示和运算-C语言中的整数类型及类型转换
* 强制类型转换
    * 有符号数和无符号数的转换
        * 不改变每一位的值，仅改变了这些位的改变方式
        * 举例
            * short x = -8
            * unsigned short y = （unsigned short）x;

        类型|比特值|数值
        --|--|--|
        x|1 1000|-8
        y|1 1000|24
    * 不同字长整数之间的转换
        * int占4B，short占2B
        * 当从大字节向小字节转换
            * 系统把多余的高位直接截断，低位直接赋值
        * 当从小字节向大字节转换
            * 不仅相应的位值相等，高位部分还会扩展为原数字的符号位
        * char（8位）转换为int时，直接在高位补0即可
* C语言的数据在内存中的存放形式是：补码存放
* 原码求补码
    * 正数
        * 不变
    * 负数
        * 数值位取反+1

## 模板
![img]()
### 解答

### 知识点背诵

## 浮点数加减法
![img](https://s1.ax1x.com/2020/10/18/0XJ6sI.jpg)
### 解答
* 浮点数的表示范围已被删除，这里的溢出不做解答
### 知识点背诵
* 计算机组成原理-数据的表示和运算-浮点数的表示和运算
* 为什么要引入浮点数？
    * 定点数的表示范围有限，其上限取决于位数，若是想要增加表示范围，只能不断提高其位数；而浮点数的出现，可以在位数有限的情况下，既扩大数的表示范围，又保持了数的有效精度
* 浮点数的格式？
    * 类比十进制：3.05*10<sup>11</sup>
    * 其中10是约定好的，我们称11为阶码，3.05为尾数，其对应的符号分别称为阶符和数符

    阶码|阶码数值部分|数符|尾数数值部分
    --|--|--|--|

    其中阶码的数值部分和阶符共同反映浮点数的表示范围和小数点的实际位置；数符代表浮点数的符号，尾数的位数n反映浮点数的精度。
    * 运算：r<sup>E</sup>*M,其中2=r通常取2，E为阶码，M为尾数；其中阶码常用补码或移码表示，尾数常用原码或补码表示
    * 例：若阶码和尾数均用补码表示，求a，b的真值
        * a=0,01；1.1001，b=0,10；0.01001
        * a的阶码E=1，尾数M=1.0111，则值为2*(-1)(2<sup>-2</sup>+2<sup>-3</sup>+2<sup>-4</sup>)
        * b的阶码E=2，尾数M=0.01001,则值为2<sup>2</sup>*(2<sup>-2</sup>+2<sup>-5</sup>)
* 浮点数的规格化
    * 两种规格化的方法
        * 左规
            * 思考科学计数法，尾数的最高位要是有效值 
            * 尾数算术左移1位，阶码减1；直到尾数的最高位是有效位
        * 右规
            * 要保证小数点跟在第一个有效位后
            * 尾数算术右移1位，阶码加1；直到满足要求 
            * 当浮点数运算结果尾数出现溢出时（双符号位为01或10）时，要进行右规
                * a=010；00.1100 b=010；00.1000
                * 求a+b 
    * 使用原码表示尾数 vs 使用补码表示尾数
        * 使用原码表示的尾数进行规格化
            * 正数0.1xxxx
            * 负数1.1xxxx
            * 最大最小值直接计算即可
        * 使用补码表示的尾数进行规格化
            * 正数：与原码一致0.1xxx
            * 负数：**1.0xxxx**（即最高的数值位必须与符号位不同，规定），最大值1.0111xx1，最小值1.0000xxx00 
        * 例：若某浮点数的阶码、尾码都用补码表示，共4+8位；0.110；1.1110100，如何规格化（补码算术左移低位补0，算术右移，高位补1）
            * 结果0.011；1.0100000
* 浮点数的表示范围（了解）
    * 发生正上溢和负上溢，发出异常
    * 发生正下溢和负下溢，当作机器0
* IEEE754标准
* 浮点数的加减法运算
## Cache和主存的映射方式
![img](https://s1.ax1x.com/2020/10/15/0TiJv8.jpg)
### 解答
* 题目中说每个主存块32个字节，按字节编址，那第129号单元就是第129号字节；129/32=4，在第四块主存块；4/（16/2）=4，应该装到的Cache号是4
### 知识点背诵
* 组成原理-存储系统-Cache和主存的映射方式
* Cache是主存中某个块的副本，地址映射是将主存地址空间映射到Cache地址空间，即将存放在主存中的信息按照某种规则装入Cache
* Cache的行数比主存块数少的多，所以主存中只有一部分块的信息可以放入Cache中
    * 因此要为每个Cache块加一个标记，指明他是主存中哪一块的副本。
    * 为了说明Cache行中信息是否有效，每个Cache行需要一个有效位
* 地址映射 vs 地址变换
    * 地址变换是CPU在访存时，根据主存地址和映射规则换算成Cache地址的**过程**
* 类别
    * 直接映射
        * 主存中的每一块只能装入Cache中的唯一位置；若该位置已有内容，则产生冲突，原来的块无条件替换出去（不需要使用替换算法）
        * 直接映射关系
            * j = i mod 2<sup>c</sup>
            * 其中2<sup>c</sup>为Cache总块数，即1，2<sup>c</sup>+1，2<sup>c+1</sup>+1等放在第一块
        * 结构

        标记|Cache行号|块内地址
        --|--|--|

        其中主存块号的低c位是他要装入的Cache行号，将主存块号的高t位放入标记。
        * 访存过程
            * 首先根据访存地址的中间c位直接找到对应的Cache行
            * 将Cache行中的标记和主存地址的高t位进行比较
                * 若相等且有效位为1，则命中
                    * 根据主存地址中低位的块内地址，在对应的Cache行存取信息
                * 若不等或有效位为0，则不命中
                    * 此时CPU从主存中读出该地址所在的一块信息送到对应的Cache行，并将有效位置1，把标记位设置为高t为，同时将该地址中的内容送入CPU
        * 评价
            * 实现简单
            * 但不够灵活，即使Cache里有其他地址空着也不能占用
            * 块冲突概率最高，空间利用率最低
            * 不需要替换算法（先来先出）
    * 全相联映射
        * 主存的每一块可以装入Cache的任何位置
        * CPU访存时需要与所有Cache行标记进行比较
        * 结构

        标记|块内地址|
        --|--|
        * 评价
            * 比较灵活
            * 块冲突概率低，空间利用率高
            * 但标记的比较速度慢，实现成本高，通常需要使用昂贵的相联存储器（内容寻址）进行地址映射
    * 组相联映射
        * 将Cache空间分为大小相同的组，组间直接映射（求余固定），组内全相联（随便放置）
            * 当分组Q=1时为全相联，分组Q=Cache数为直接映射
        * r路组相联
            * 每个组有r个Cache行
        * 映射关系
            * j = i mod Q
            * j为Cache行的组号，i为主存块号，Q为组数
        * 路数越多，发生冲突概率越小，但成本越接近全相联，要选择合适的路数
        * 结构

        标记|组号|块内地址|
        --|--|--|
        * 访存过程
            * 用访存地址中间的组号找到对应的Cache组
            * 将对应Cache组中每个行的标记和高位标记进行比较
                * 若相等且有效位为1，则命中，读取信息
                * 若不相等或者有效位不为1，则不命中
                    * CPU从主存中读取相应地址的信息送到对应Cache组的一个空闲行，并将有效位置1，同时将内容送入CPU

## 数据寻址后PC的地址
![img](https://s1.ax1x.com/2020/10/17/0LfwPH.jpg)
### 解答
* 每取一个字节PC自动加1，转移指令由两字节组成，并且机器字长也是两字节，所以取完PC+2

## 单处理机
![img](https://s1.ax1x.com/2020/10/17/0LhdmV.jpg)
### 解答
* 要理解并发vs并行
    * 并行是指在同一时刻同时执行
    * 并发是指在同一时间段内很快的交替执行
* 单处理机同一时刻只能运行一个进程，故不能实现进程间的并行
* 而设备可以使用特定的设备控制方式和处理机并行，I/O通道是专门负责输入/输出的处理机，故可以与处理机CPU之间并行

## 死锁
![img](https://s1.ax1x.com/2020/10/17/0L4mh4.jpg)
### 解答
### 知识点背诵
* 操作系统-进程管理-死锁
* 什么是死锁？
    * 多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都无法向前推进
* 为什么会产生死锁？
    * 多个进程竞争不可剥夺资源，且资源数量不足（对可剥夺资源的竞争不会引起死锁）
    * 进程推进顺序非法——请求和释放资源顺序不当
        * 信号量使用不当也会造成死锁——互相等消息，互相不开始，陷入僵局
* 产生的四个必要条件
    * 互斥条件
        * 进程要求分配的资源是排他的，最多同时供一个进程使用
    * 不可剥夺条件
        * 进程使用完资源之前，资源不可被强制夺走
    * 请求并保持条件
        * 进程占有自身本来的资源并要求其他资源
    * 循环等待条件
        * 存在一种进程资源的循环等待链
* 解决方法
    * 死锁预防（从根源上使死锁不会发生）
        * 破坏死锁的四个必要条件
            * 互斥条件在有些设备下，不应该被更改，故行不通
            * 破坏不可剥夺，当保持了不可剥夺资源的进行请求新的资源得不到满足时，就需要放弃所有资源，这样会导致前面一段时间的工作失效，反复申请和释放资源会增加系统开销，降低系统吞吐量。
                * 常用于状态易于保存和恢复的资源，如CPU的寄存器及内存资源，不可用于打印机
            * 破坏请求并等待，使用预先静态分配的方法，给进程一次分配所有资源，不满不运行，实现简单，但是系统资源被严重浪费，有些资源到进程快结束才使用，或者根本不使用；而且会导致“饥饿”，个别资源长期被其他进程占用，导致等待该资源的进程迟迟不能运行。
            * 破坏循环等待，采用顺序资源分分配法，给资源编号，只能按照编号递增的顺序请求资源，同类资源一次分配完。
                * 限制了新类型设备的增加，若进程执行前资源使用顺序未考虑清楚，会造成资源浪费；给用户编程带来困难
    * 死锁避免
        * 在资源动态分配过程中，阻止系统进入不安全状态
            * 不安全状态并非一定发生死锁，但只要处于安全状态，就一定不会发生死锁
            * 能够找到一个安全序列则就处于安全状态
        * 银行家算法 
            * 涉及多种资源，使用向量表示（n个进程，m个资源）

            进程|最大需求|已分配|最多还需要
            --|--|--|--|
            别名|max|allocation|need|
            p0|(7,5,3)|(2,2,1)|(5,3,2)
            p1|(3,2,2)|(2,0,0)|(1,2,2)
            p2|(9,0,2)|(3,0,2)|(6,0,0)
            p3|(2,2,2)|(2,1,1)|(0,1,1)
            p4|(4,3,3)|(0,0,2)|(4,3,1)

            此时available = (2,2,1)
            出现一个请求Request<sub>0</sub>=（2,1,1），是否分配

            * 步骤
                1. 先用request和need进行比较，存在need<request则进行2，否则不分配
                2. 用request和available进行比较，若request<available则分配，否则不分配
                3. 系统尝试进行完成p0的请求（并非着真的分配，修改数值是为了做预判）
                4. 执行安全性算法，检查进行分配后系统是否处于安全状态，若安全则分配，否则，就阻塞
    * 死锁的检测与解除（事后处理）
        * 资源分配图
        ![img](https://s1.ax1x.com/2020/10/17/0L7WnA.jpg)
            * 圆圈代表进程，框代表一类资源，框中的圆代表一类资源中的一个资源
            * 从进程到资源的称为请求边，资源到进程称为分配边
        *  死锁定理
            * 对于资源分配图，找到一个不孤立的点，且系统中已有的空闲资源的数量大于等于其请求的对应资源的数量，则将与其相连的边抹去
            * 然后寻找新的点，进行相同的操作
            * 若能消去所有的边，则称该图可以完全简化，否则存在死锁
        * 死锁解除
            * 资源剥夺法
                * 挂起某些死锁进程，剥夺其资源，将资源分配给其他死锁进程
            * 撤销进程法
                * 强制撤销部分甚至全部死锁进程并剥夺这些进程的资源。（注意撤销和挂起的区别）
                    * 可以按照进程的优先级和撤销进程代价的高低进行
            * 进程回退法
                * 让一个或者多个进程回退到足以避免死锁的地步，进程回退时自愿释放资源而非被剥夺。
                    * 要求系统保持进程的历史信息，设置还原点
## 文件共享相关问题
![img](https://s1.ax1x.com/2020/10/17/0LqMmd.jpg)
### 解答
* 先考虑硬链接，建立硬链接，引用计数器count+1，删除时count-1，实际上若count-1$\not=$0，不可以删除文件，只能把count-1，将用户目录中的目录项删除，故计数值此时为1
* 对于软链接，删除和建立对各个用户都不可见，只有在访问失效时，才会将符号链删除，故直接复制引用计数值，新建软链接，count不变，删除文件，count不变。
### 知识点背诵
* 操作系统-文件管理-文件共享
* 文件共享是什么？
    * 文件共享使多个用户共享同一文件，系统中只用保留该文件的一个副本。若系统不提供共享功能，则每个需要该文件的用户都要有各自的副本，对存储空间造成极大的浪费。
    * 目前的共享方式已经从单机系统发展到多机系统，进而通过网络扩展到全球，这些文件共享通过分布式文件系统、远程文件系统、分布式信息系统实现的，这些系统允许多个用户通过c/s模型共享网络中的服务器文件
* 文件共享方法？
    * 基于索引节点的共享方式（硬链接）
        * 在树形结构的目录中，当有两个或者多个用户要共享一个子目录或文件时，必须将共享文件或子目录链接到两个或者多个用户的目录中，才能方便的找到该文件。
        * 此时，文件的物理地址及其他文件属性等信息，不再放在目录项中，而是放在索引节点中；文件目录中只设置文件名及指向相应索引结点的指针。
        * 在索引结点中还有一个链接计数count，用于表示链接到本索引结点上的用户目录项的数目.
        * 创立及删除过程
            * 用户A创立一个新文件，为文件所有者，此时将count设为1.若用户B想要共享此文件，在用户B的目录中增加一个目录项，设置一个指针指向该文件的索引结点，count=2.
            * 此时文件主依然是A
            * 若用户A不需要此文件，也不可以删除，否则B的指针会悬空。所以A执行的操作是
                * count-1
                * 然后删除自己目录中的目录项
            * 当count=0时，由系统负责删除该文件
    * 利用符号链的共享方式（软链接）
        * 当B要共享A的F文件，由系统创建一个同样名为F的LINK类型新文件，写入目录B的目录中，新文件中只包含被链接文件F的路径名，称为符号链。
        * B要访问F则会访问同样名为F的LINK类型新文件，操作系统根据新文件中的路径名去读该文件，实现共享
        * 只有文件拥有才拥有索引指针，其他共享用户只有路径名；故当文件拥有者将文件删除，其他用户按照路径访问，会出现访问失败，然后将符号链删除即可，不产生任何影响
        * 存在问题
            * 若是文件拥有者将文件删除，共享的其他用户使用符号链访问该文件之前，又有人在同一路径（参考网址）创建了另一个具有相同名称的文件，则符号链依然有效，但是访问的文件已经变化了，导致错误。
            * 其他用户读共享文件时，需要根据文件路径名逐个查找目录，直到找到索引结点。即每次访问都要多次读盘，系统开销大。
    * 总结
        * 均为静态共享方法，若是想要满足两个进程同时对一个文件进行操作，称为动态共享。
        * 硬链接查找速度较软链接快
## 拥塞控制
![img](https://s1.ax1x.com/2020/10/17/0O9YaF.jpg)
### 解答
* 出现超时执行慢开始和拥塞避免，门限值设置为拥塞窗口的一半，为8KB，执行慢开始，拥塞窗口设为1，并指数增加，第一个RTT，为2，第二个RTT，为4，第三个RTT，为8，此时达到门限值，执行拥塞避免，第四个RTT，加1，为9
### 知识点背诵
* 计算机网络-传输层-TCP拥塞控制
* 什么是拥塞控制？
    * 是指防止过多的数据注入网络，保证网络中的路由器或链路不致过载。
    * 端点并不了解拥塞发生的细节，一般只表现为通信时延增加
* 拥塞控制vs流量控制
    * 流量控制着重于点对点，拥塞控制着重于全局
    * 流量控制中，发送方发送数据的量由接收方决定；拥塞控制中，主要由发送的拥塞窗口决定。
    * 相同：都是通过**控制发送方发送数据的速率**来达到控制效果
* 拥塞窗口vs接收窗口
    * 拥塞窗口cwnd，**发送方**根据**自己估算**的网络拥塞程度而设置的窗口值，**反映当前网络容量**。
        * 网络未拥塞，就增大一些；拥塞，就减少一些
    * 接收窗口rwnd，**接收方**根据目前接收缓存大小所许诺的最新窗口值，**反映接收方的容量**
    * 发送窗口的上限取决于两者间的最小值；但是一般约定接收方总有足够的大的容量，所以考虑之后的算法将发送窗口等同于拥塞窗口
* 拥塞控制的四种算法
    * 慢开始
    * 拥塞避免
    * 快重传
    * 快恢复
* 图解四种算法
    * 慢开始和拥塞避免
![img](https://s1.ax1x.com/2020/10/17/0OP2jI.jpg)
        * 慢开始，拥塞窗口由1开始指数增加（这里的慢是指从1开始）
        * 直到达到ssthresh慢开始门限（事先设定好的），执行拥塞避免，即拥塞窗口一次加1
        * 若出现网络拥塞，ssthresh=(1/2)*拥塞前的拥塞窗口（不能小于2）,重新执行慢开始
    * 快重传和快恢复（对慢开始和拥塞避免的改进）
    ![img](https://s1.ax1x.com/2020/10/17/0OiORH.jpg)
        * 在出现快重传之前也是慢开始和拥塞避免，区别在于对网络拥塞的判断依据和网络拥塞后的处理方法不同
        * 快重传使用了冗余ACK——当发送方连续收到三个重复的ACK报文时，直接重传对方尚未收到的报文段，不用等那个报文段设置的重传计时器超时。
        * 快恢复：执行乘法减少，ssthresh=(1/2)*拥塞前的拥塞窗口（不能小于2），但是不重新执行慢开始，拥塞窗口不从1开始，而是从ssthresh开始，执行加1（有点像直接进入拥塞避免算法），这种做法称为快恢复。
    * 总结，超时的时候执行慢开始和拥塞避免，冗余ACK时执行快重传和快恢复。